{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語数: 5256\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# MeCabの初期化（分かち書き用）\n",
    "mecab = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "# ファイルパス\n",
    "fp_comments = 'comments.txt'\n",
    "fp_word_to_id = 'word_to_id.pkl'\n",
    "fp_id_to_word = 'id_to_word.pkl'\n",
    "\n",
    "# comments.txt の読み込み\n",
    "with open(fp_comments, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 文部分のみ抽出（index:文 → 文）\n",
    "comments = [re.sub(r'^\\d+:', '', line).strip() for line in lines]\n",
    "\n",
    "# 分かち書きしてトークンリストを作成\n",
    "tokens = []\n",
    "for comment in comments:\n",
    "    words = mecab.parse(comment).strip().split()  # 分かち書き実行\n",
    "    tokens.extend(words)\n",
    "\n",
    "# 句読点などの不要文字を削除\n",
    "table = str.maketrans({'.': '', ',': '', '。': '', '、': '', '「': '', '」': '', '（': '', '）': ''})\n",
    "tokens = [word.translate(table) for word in tokens]\n",
    "\n",
    "# 単語の頻度カウント\n",
    "freq = Counter(tokens)\n",
    "\n",
    "# 3回以上出現する単語のみ抽出\n",
    "vocab_kif = [token for token, count in freq.items() if count >= 3]\n",
    "vocab_kif.sort()\n",
    "\n",
    "# 特殊トークンの追加\n",
    "vocab_kif.extend(['<start>', '<end>', '<unk>', '<null>'])\n",
    "\n",
    "# 単語IDマッピングの作成\n",
    "word_to_id = {token: i for i, token in enumerate(vocab_kif)}\n",
    "id_to_word = {i: token for i, token in enumerate(vocab_kif)}\n",
    "\n",
    "# 辞書ファイルの保存\n",
    "with open(fp_word_to_id, 'wb') as f:\n",
    "    pickle.dump(word_to_id, f)\n",
    "with open(fp_id_to_word, 'wb') as f:\n",
    "    pickle.dump(id_to_word, f)\n",
    "\n",
    "print(f'単語数: {len(word_to_id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cshogi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': '２二', 'same': '同', 'piece': '歩', 'suffix': '', 'motion': '成', 'from': None}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r\"\"\"\n",
    "    ([１-９1-9一二三四五六七八九]{2})?      # 移動先\n",
    "    (?P<same>同)?                                # 同\n",
    "    \\s*                                         # 空白文字\n",
    "    (?P<piece>成[銀桂香]|[王玉金銀全桂圭香杏角馬飛龍竜歩と])  # 駒\n",
    "    (?P<suffix>[左右直]?[寄引上行]?)               # 駒の動きの接尾辞\n",
    "    (?P<motion>不?成|打|合|生)?                   # 動きの種類\n",
    "\"\"\"\n",
    "\n",
    "# テスト用の文字列\n",
    "test_string = \"２二同歩成\"\n",
    "\n",
    "# 正規表現をコンパイルして、テスト文字列にマッチさせる\n",
    "match = re.match(pattern, test_string, re.VERBOSE)\n",
    "\n",
    "if match:\n",
    "    print(match.groupdict())\n",
    "else:\n",
    "    print(\"マッチしませんでした\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = r\"\"\"\n",
    "    [▲△]                           # 手番（▲または△）\n",
    "    \\d{1,2}\\s?\\d{1,2}?              # 移動元（オプション）\n",
    "    同?                              # 同\n",
    "    (歩|銀|金|角|飛|歩と|銀と|金と|桂|香|角成|飛成|竜|馬)?  # 駒\n",
    "    (不成|打|成)?                    # 駒の動き（不成、打、成）\n",
    "    \\d{1,2}\\s?\\d{1,2}                 # 移動先\n",
    "    [左右直寄引上行]?                # 駒の動きの接尾辞\n",
    "\"\"\"\n",
    "\n",
    "# テスト用の文字列\n",
    "test_string = \"▲4五歩△同歩▲3三歩不成△7七歩成▲同銀左△7六金打\"\n",
    "\n",
    "# 正規表現をコンパイルして、テスト文字列にマッチさせる\n",
    "matches = re.findall(pattern, test_string, re.VERBOSE)\n",
    "\n",
    "# 一致する部分を出力\n",
    "for match in matches:\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▲', '1', '七', '同桂', 'は', '△', '1', '八', '歩', '▲', '同香', '△', '4', '五角', 'が', 'ある', '。']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "def tokenize_shogi_text(text, pattern):\n",
    "    # 駒の動きを一度に取得し、文中にスペースを挿入\n",
    "    shogi_moves = re.findall(pattern, text)\n",
    "    for move in shogi_moves:\n",
    "        text = text.replace(move, f\" {move} \")\n",
    "\n",
    "    # MeCabによる分かち書き\n",
    "    mecab = MeCab.Tagger(\"-Owakati\")\n",
    "    tokens = mecab.parse(text).strip().split()\n",
    "    \n",
    "    # 駒の動きを結合する処理\n",
    "    combined_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # 駒の動きに該当する部分を結合\n",
    "        if re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同(桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?\", tokens[i]):\n",
    "            combined_move = tokens[i]\n",
    "            i += 1\n",
    "            while i < len(tokens) and not re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同\", tokens[i]):\n",
    "                combined_move += tokens[i]\n",
    "                i += 1\n",
    "            combined_tokens.append(combined_move)\n",
    "        else:\n",
    "            combined_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "# テスト\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "pattern = r\"\"\"\n",
    "    [▲△]                           # 手番（▲または△）\n",
    "    \\d{1,2}\\s?\\d{1,2}?              # 移動元（オプション）\n",
    "    同                              # 同\n",
    "    (桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?  # 駒\n",
    "    (不成|打|成)?                    # 駒の動き（不成、打、成）\n",
    "    \\d{1,2}\\s?\\d{1,2}                 # 移動先\n",
    "    [左右直寄引上行]?                # 駒の動きの接尾辞\n",
    "\"\"\"\n",
    "tokens = tokenize_shogi_text(text, pattern)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▲', '1', '七', '同桂', 'は', '△', '1', '八', '歩', '▲', '同香', '△', '4', '五角', 'が', 'ある', '。']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "def tokenize_shogi_text(text, pattern):\n",
    "    # 駒の動きを一度に取得し、文中にスペースを挿入\n",
    "    shogi_moves = re.findall(pattern, text)\n",
    "    for move in shogi_moves:\n",
    "        text = text.replace(move, f\" {move} \")\n",
    "\n",
    "    # MeCabによる分かち書き\n",
    "    mecab = MeCab.Tagger(\"-Owakati\")\n",
    "    tokens = mecab.parse(text).strip().split()\n",
    "    \n",
    "    # 駒の動きを結合する処理\n",
    "    combined_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # 駒の動きに該当する部分を結合\n",
    "        if re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同(桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?\", tokens[i]):\n",
    "            combined_move = tokens[i]\n",
    "            i += 1\n",
    "            while i < len(tokens) and not re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同\", tokens[i]):\n",
    "                combined_move += tokens[i]\n",
    "                i += 1\n",
    "            combined_tokens.append(combined_move)\n",
    "        else:\n",
    "            combined_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "# テスト\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "pattern = r\"\"\"\n",
    "    [▲△]                           # 手番（▲または△）\n",
    "    \\d{1,2}\\s?\\d{1,2}?              # 移動元（オプション）\n",
    "    同                              # 同\n",
    "    (桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?  # 駒\n",
    "    (不成|打|成)?                    # 駒の動き（不成、打、成）\n",
    "    \\d{1,2}\\s?\\d{1,2}                 # 移動先\n",
    "    [左右直寄引上行]?                # 駒の動きの接尾辞\n",
    "\"\"\"\n",
    "tokens = tokenize_shogi_text(text, pattern)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
