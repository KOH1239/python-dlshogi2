{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語数: 5256\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# MeCabの初期化（分かち書き用）\n",
    "mecab = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "# ファイルパス\n",
    "fp_comments = 'comments.txt'\n",
    "fp_word_to_id = 'word_to_id.pkl'\n",
    "fp_id_to_word = 'id_to_word.pkl'\n",
    "\n",
    "# comments.txt の読み込み\n",
    "with open(fp_comments, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 文部分のみ抽出（index:文 → 文）\n",
    "comments = [re.sub(r'^\\d+:', '', line).strip() for line in lines]\n",
    "\n",
    "# 分かち書きしてトークンリストを作成\n",
    "tokens = []\n",
    "for comment in comments:\n",
    "    words = mecab.parse(comment).strip().split()  # 分かち書き実行\n",
    "    tokens.extend(words)\n",
    "\n",
    "# 句読点などの不要文字を削除\n",
    "table = str.maketrans({'.': '', ',': '', '。': '', '、': '', '「': '', '」': '', '（': '', '）': ''})\n",
    "tokens = [word.translate(table) for word in tokens]\n",
    "\n",
    "# 単語の頻度カウント\n",
    "freq = Counter(tokens)\n",
    "\n",
    "# 3回以上出現する単語のみ抽出\n",
    "vocab_kif = [token for token, count in freq.items() if count >= 3]\n",
    "vocab_kif.sort()\n",
    "\n",
    "# 特殊トークンの追加\n",
    "vocab_kif.extend(['<start>', '<end>', '<unk>', '<null>'])\n",
    "\n",
    "# 単語IDマッピングの作成\n",
    "word_to_id = {token: i for i, token in enumerate(vocab_kif)}\n",
    "id_to_word = {i: token for i, token in enumerate(vocab_kif)}\n",
    "\n",
    "# 辞書ファイルの保存\n",
    "with open(fp_word_to_id, 'wb') as f:\n",
    "    pickle.dump(word_to_id, f)\n",
    "with open(fp_id_to_word, 'wb') as f:\n",
    "    pickle.dump(id_to_word, f)\n",
    "\n",
    "print(f'単語数: {len(word_to_id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cshogi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': '２二', 'same': '同', 'piece': '歩', 'suffix': '', 'motion': '成', 'from': None}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r\"\"\"\n",
    "    ([１-９1-9一二三四五六七八九]{2})?      # 移動先\n",
    "    (?P<same>同)?                                # 同\n",
    "    \\s*                                         # 空白文字\n",
    "    (?P<piece>成[銀桂香]|[王玉金銀全桂圭香杏角馬飛龍竜歩と])  # 駒\n",
    "    (?P<suffix>[左右直]?[寄引上行]?)               # 駒の動きの接尾辞\n",
    "    (?P<motion>不?成|打|合|生)?                   # 動きの種類\n",
    "\"\"\"\n",
    "\n",
    "# テスト用の文字列\n",
    "test_string = \"２二同歩成\"\n",
    "\n",
    "# 正規表現をコンパイルして、テスト文字列にマッチさせる\n",
    "match = re.match(pattern, test_string, re.VERBOSE)\n",
    "\n",
    "if match:\n",
    "    print(match.groupdict())\n",
    "else:\n",
    "    print(\"マッチしませんでした\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = r\"\"\"\n",
    "    [▲△]                           # 手番（▲または△）\n",
    "    \\d{1,2}\\s?\\d{1,2}?              # 移動元（オプション）\n",
    "    同?                              # 同\n",
    "    (歩|銀|金|角|飛|歩と|銀と|金と|桂|香|角成|飛成|竜|馬)?  # 駒\n",
    "    (不成|打|成)?                    # 駒の動き（不成、打、成）\n",
    "    \\d{1,2}\\s?\\d{1,2}                 # 移動先\n",
    "    [左右直寄引上行]?                # 駒の動きの接尾辞\n",
    "\"\"\"\n",
    "\n",
    "# テスト用の文字列\n",
    "test_string = \"▲4五歩△同歩▲3三歩不成△7七歩成▲同銀左△7六金打\"\n",
    "\n",
    "# 正規表現をコンパイルして、テスト文字列にマッチさせる\n",
    "matches = re.findall(pattern, test_string, re.VERBOSE)\n",
    "\n",
    "# 一致する部分を出力\n",
    "for match in matches:\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▲', '1', '七', '同桂', 'は', '△', '1', '八', '歩', '▲', '同香', '△', '4', '五角', 'が', 'ある', '。']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "def tokenize_shogi_text(text, pattern):\n",
    "    # 駒の動きを一度に取得し、文中にスペースを挿入\n",
    "    shogi_moves = re.findall(pattern, text)\n",
    "    for move in shogi_moves:\n",
    "        text = text.replace(move, f\" {move} \")\n",
    "\n",
    "    # MeCabによる分かち書き\n",
    "    mecab = MeCab.Tagger(\"-Owakati\")\n",
    "    tokens = mecab.parse(text).strip().split()\n",
    "    \n",
    "    # 駒の動きを結合する処理\n",
    "    combined_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # 駒の動きに該当する部分を結合\n",
    "        if re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同(桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?\", tokens[i]):\n",
    "            combined_move = tokens[i]\n",
    "            i += 1\n",
    "            while i < len(tokens) and not re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同\", tokens[i]):\n",
    "                combined_move += tokens[i]\n",
    "                i += 1\n",
    "            combined_tokens.append(combined_move)\n",
    "        else:\n",
    "            combined_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "# テスト\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "pattern = r\"\"\"\n",
    "    [▲△]                           # 手番（▲または△）\n",
    "    \\d{1,2}\\s?\\d{1,2}?              # 移動元（オプション）\n",
    "    同                              # 同\n",
    "    (桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?  # 駒\n",
    "    (不成|打|成)?                    # 駒の動き（不成、打、成）\n",
    "    \\d{1,2}\\s?\\d{1,2}                 # 移動先\n",
    "    [左右直寄引上行]?                # 駒の動きの接尾辞\n",
    "\"\"\"\n",
    "tokens = tokenize_shogi_text(text, pattern)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▲', '1', '七', '同桂', 'は', '△', '1', '八', '歩', '▲', '同香', '△', '4', '五角', 'が', 'ある', '。']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "def tokenize_shogi_text(text, pattern):\n",
    "    # 駒の動きを一度に取得し、文中にスペースを挿入\n",
    "    shogi_moves = re.findall(pattern, text)\n",
    "    for move in shogi_moves:\n",
    "        text = text.replace(move, f\" {move} \")\n",
    "\n",
    "    # MeCabによる分かち書き\n",
    "    mecab = MeCab.Tagger(\"-Owakati\")\n",
    "    tokens = mecab.parse(text).strip().split()\n",
    "    \n",
    "    # 駒の動きを結合する処理\n",
    "    combined_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # 駒の動きに該当する部分を結合\n",
    "        if re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同(桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?\", tokens[i]):\n",
    "            combined_move = tokens[i]\n",
    "            i += 1\n",
    "            while i < len(tokens) and not re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九]+同\", tokens[i]):\n",
    "                combined_move += tokens[i]\n",
    "                i += 1\n",
    "            combined_tokens.append(combined_move)\n",
    "        else:\n",
    "            combined_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "# テスト\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "pattern = r\"\"\"\n",
    "    [▲△]                           # 手番（▲または△）\n",
    "    \\d{1,2}\\s?\\d{1,2}?              # 移動元（オプション）\n",
    "    同                              # 同\n",
    "    (桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?  # 駒\n",
    "    (不成|打|成)?                    # 駒の動き（不成、打、成）\n",
    "    \\d{1,2}\\s?\\d{1,2}                 # 移動先\n",
    "    [左右直寄引上行]?                # 駒の動きの接尾辞\n",
    "\"\"\"\n",
    "tokens = tokenize_shogi_text(text, pattern)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('▲', '1七', '同', '桂', '桂', '', ''), ('△', '1八', '', '歩', '歩', '', ''), ('△', '4五', '', '角', '角', '', '')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "\n",
    "pattern = r\"([▲△])(\\d{1,2}[一二三四五六七八九十]+)([同]?)(([桂香銀金角飛歩と成香成桂成銀竜馬]?(不成|打|成)?[左右直寄引上行]?)(\\d{1,2}[一二三四五六七八九十]+[左右直寄引上行]?)?)\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('▲', '1七', '同', '桂', '桂', '', '')\n",
      "('△', '1八', '', '歩', '歩', '', '')\n",
      "('△', '4五', '', '角', '角', '', '')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "def tokenize_shogi_text(text):\n",
    "    \"\"\"将棋棋譜のテキストをトークン化します。\n",
    "\n",
    "    Args:\n",
    "        text (str): 将棋棋譜のテキスト\n",
    "\n",
    "    Returns:\n",
    "        list: トークン化された指し手のリスト\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = r\"([▲△])(\\d{1,2}[一二三四五六七八九十]+)([同]?)(([桂香銀金角飛歩と成香成桂成銀竜馬]?(不成|打|成)?[左右直寄引上行]?)(\\d{1,2}[一二三四五六七八九十]+[左右直寄引上行]?)?)\"\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    return matches\n",
    "\n",
    "# テスト\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "tokens = tokenize_shogi_text(text)\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▲', '1', '七', '同桂', '△', '1', '八', '歩', '△', '4', '五角', 'は', '▲', '同香', 'が', 'ある', '。']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "def tokenize_shogi_text(text):\n",
    "    \"\"\"将棋棋譜のテキストを自然な日本語で分かち書きします。\n",
    "\n",
    "    Args:\n",
    "        text (str): 将棋棋譜のテキスト\n",
    "\n",
    "    Returns:\n",
    "        list: 分かち書きされた単語のリスト\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = r\"([▲△])(\\d{1,2}[一二三四五六七八九]+)([同]?)(([玉桂香銀金角飛歩と成香成桂成銀竜馬]?(不成|打|成)?[左右直寄引上行]?)(\\d{1,2}[一二三四五六七八九]+[左右直寄引上行]?)?)\"\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    mecab = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "    result = []\n",
    "    for match in matches:\n",
    "        result.extend(mecab.parse(match[0] + match[1] + match[2] + match[3]).strip().split())\n",
    "\n",
    "    # 残りのテキストを分かち書き\n",
    "    rest_text = re.sub(pattern, '', text).strip()\n",
    "    result.extend(mecab.parse(rest_text).strip().split())\n",
    "\n",
    "    return result\n",
    "\n",
    "# テスト\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "tokens = tokenize_shogi_text(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▲', '1', '七', '同桂', 'は', '△', '1', '八', '歩', '▲', '同香', '△', '4', '五角', 'が', 'ある', '。']\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "# MeCabのセットアップ\n",
    "mecab = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "# 文章\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "\n",
    "# 単語の分割（分かち書き）\n",
    "tokens = mecab.parse(text).strip().split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▲', '1', '七', '同桂', 'は', '△', '1', '八', '歩', '▲', '同香', '△', '4', '五角', 'が', 'ある', '。']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "def tokenize_shogi_text(text, pattern):\n",
    "    # 駒の動きを先に結合\n",
    "    shogi_moves = re.findall(pattern, text)\n",
    "    for move in shogi_moves:\n",
    "        text = text.replace(move, f\" {move} \")\n",
    "\n",
    "    # MeCabによる分かち書き\n",
    "    mecab = MeCab.Tagger(\"-Owakati\")\n",
    "    tokens = mecab.parse(text).strip().split()\n",
    "    \n",
    "    # 駒の動きを結合する処理\n",
    "    combined_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # 駒の動きに該当する部分を結合\n",
    "        if re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同(桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?\", tokens[i]):\n",
    "            combined_move = tokens[i]\n",
    "            i += 1\n",
    "            while i < len(tokens) and not re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同\", tokens[i]):\n",
    "                combined_move += tokens[i]\n",
    "                i += 1\n",
    "            combined_tokens.append(combined_move)\n",
    "        else:\n",
    "            combined_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "# 文章\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "\n",
    "# 駒の動きを結合するための正規表現\n",
    "pattern = r\"\"\"\n",
    "    [▲△]                           # 手番（▲または△）\n",
    "    \\d{1,2}\\s?\\d{1,2}?              # 移動元（オプション）\n",
    "    同                              # 同\n",
    "    (桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?  # 駒\n",
    "    (不成|打|成)?                    # 駒の動き（不成、打、成）\n",
    "    \\d{1,2}\\s?\\d{1,2}                 # 移動先\n",
    "    [左右直寄引上行]?                # 駒の動きの接尾辞\n",
    "\"\"\"\n",
    "\n",
    "# トークン化\n",
    "tokens = tokenize_shogi_text(text, pattern)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▲', '1', '七', '同桂', 'は', '△', '1', '八', '歩', '▲', '同香', '△', '4', '五角', 'が', 'ある', '。']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "def tokenize_shogi_text(text, pattern):\n",
    "    # MeCabによる分かち書き\n",
    "    mecab = MeCab.Tagger(\"-Owakati\")\n",
    "    tokens = mecab.parse(text).strip().split()\n",
    "    \n",
    "    # 駒の動きを結合する処理\n",
    "    combined_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # 駒の動きに該当する部分を結合（▲1七同桂など）\n",
    "        if re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同(桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?\", tokens[i]):\n",
    "            combined_move = tokens[i]\n",
    "            i += 1\n",
    "            while i < len(tokens) and not re.match(r\"^[▲△]\\d{1,2}[一二三四五六七八九十]+同\", tokens[i]):\n",
    "                combined_move += tokens[i]\n",
    "                i += 1\n",
    "            combined_tokens.append(combined_move)\n",
    "        else:\n",
    "            combined_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "# 文章\n",
    "text = \"▲1七同桂は△1八歩▲同香△4五角がある。\"\n",
    "\n",
    "# 駒の動きに該当する正規表現（駒の動きを検出）\n",
    "pattern = r\"\"\"\n",
    "    [▲△]                           # 手番（▲または△）\n",
    "    \\d{1,2}\\s?\\d{1,2}?              # 移動元（オプション）\n",
    "    同                              # 同\n",
    "    (桂|香|銀|金|角|飛|歩|と|成香|成桂|成銀|角成|飛成|竜|馬)?  # 駒\n",
    "    (不成|打|成)?                    # 駒の動き（不成、打、成）\n",
    "    \\d{1,2}\\s?\\d{1,2}                 # 移動先\n",
    "    [左右直寄引上行]?                # 駒の動きの接尾辞\n",
    "\"\"\"\n",
    "\n",
    "# トークン化\n",
    "tokens = tokenize_shogi_text(text, pattern)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('▲', '4五', '4', '五', '', '歩', '', '', ''), ('△', '同', '', '', '', '歩', '', '', ''), ('▲', '3三', '3', '三', '', '歩', '', '', '不成'), ('△', '7七', '7', '七', '', '歩', '', '', '成'), ('▲', '同', '', '', '', '銀', '左', '', ''), ('△', '7六', '7', '六', '', '金', '', '', '打')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# テストテキスト\n",
    "text = \"▲4五歩△同歩▲3三歩不成△7七歩成▲同銀左△7六金打\"\n",
    "\n",
    "# 正規表現を使って駒の動き部分を抽出\n",
    "pattern = r\"\"\"\n",
    "    (▲|△)                               # 手番（▲または△）\n",
    "    (                                     # グループ開始\n",
    "        (1|2|3|4|5|6|7|8|9)        # 数字（１〜９）\n",
    "        (一|二|三|四|五|六|七|八|九)    # 漢数字（いち、に、さん、し、ご、ろく、しち、はち、きゅう）\n",
    "        | 同                               # 同\n",
    "        | (同){1,2}                        # 同（1回または2回）\n",
    "    )                                     # グループ終了\n",
    "    (王|玉|飛|龍|竜|角|馬|金|銀|成銀|桂|成桂|香|成香|歩|と)  # 駒の種類\n",
    "    (左|右)?                             # 駒の動き方向（左、右）\n",
    "    (上|直|引|寄)?                       # 駒の動きの接尾辞（上、直、引、寄）\n",
    "    (成|不成|打)?                        # 駒の動きの詳細（成、不成、打）\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 正規表現にマッチする部分を抽出\n",
    "matches = re.findall(pattern, text, re.VERBOSE)\n",
    "\n",
    "# 結果を表示\n",
    "print(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
